{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noball']\n",
      "noball\n",
      "1.jpg\n",
      "10.jpg\n",
      "100.jpg\n",
      "11.jpg\n",
      "12.jpg\n",
      "13.jpg\n",
      "14.jpg\n",
      "15.jpg\n",
      "16.jpg\n",
      "17.jpg\n",
      "18.jpg\n",
      "19.jpg\n",
      "2.jpg\n",
      "20.jpg\n",
      "21.jpg\n",
      "22.jpg\n",
      "23.jpg\n",
      "24.jpg\n",
      "25.jpg\n",
      "26.jpg\n",
      "27.jpg\n",
      "28.jpg\n",
      "29.jpg\n",
      "3.jpg\n",
      "30.jpg\n",
      "31.jpg\n",
      "32.jpg\n",
      "33.jpg\n",
      "34.jpg\n",
      "35.jpg\n",
      "36.jpg\n",
      "37.jpg\n",
      "38.jpg\n",
      "39.jpg\n",
      "4.jpg\n",
      "40.jpg\n",
      "41.jpg\n",
      "42.jpg\n",
      "43.jpg\n",
      "44.jpg\n",
      "45.jpg\n",
      "46.jpg\n",
      "47.jpg\n",
      "48.jpg\n",
      "49.jpg\n",
      "5.jpg\n",
      "50.jpg\n",
      "51.jpg\n",
      "52.jpg\n",
      "53.jpg\n",
      "54.jpg\n",
      "55.jpg\n",
      "56.jpg\n",
      "57.jpg\n",
      "58.jpg\n",
      "59.jpg\n",
      "6.jpg\n",
      "60.jpg\n",
      "61.jpg\n",
      "62.jpg\n",
      "63.jpg\n",
      "64.jpg\n",
      "65.jpg\n",
      "66.jpg\n",
      "67.jpg\n",
      "68.jpg\n",
      "69.jpg\n",
      "7.jpg\n",
      "70.jpg\n",
      "71.jpg\n",
      "72.jpg\n",
      "73.jpg\n",
      "74.jpg\n",
      "75.jpg\n",
      "76.jpg\n",
      "77.jpg\n",
      "78.jpg\n",
      "79.jpg\n",
      "8.jpg\n",
      "80.jpg\n",
      "81.jpg\n",
      "82.jpg\n",
      "83.jpg\n",
      "84.jpg\n",
      "85.jpg\n",
      "86.jpg\n",
      "87.jpg\n",
      "88.jpg\n",
      "89.jpg\n",
      "9.jpg\n",
      "90.jpg\n",
      "91.jpg\n",
      "92.jpg\n",
      "93.jpg\n",
      "94.jpg\n",
      "95.jpg\n",
      "96.jpg\n",
      "97.jpg\n",
      "98.jpg\n",
      "99.jpg\n"
     ]
    }
   ],
   "source": [
    "#..................................................Preprocessing of images............................................#\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = 'Dataset/'\n",
    "#we specify where the data is to be taken for preprocessing\n",
    "path2 = 'Preprocessed/Train/'\n",
    "#This is the directory where the preprocessed picture will be saved\n",
    "#We need to create this directory\n",
    "\n",
    "gestures = os.listdir(path)\n",
    "#os.listdir() method in python is used to get the list of all files and directories in the specified directory.\n",
    "#This will take all the folders and files in Dataset\n",
    "\n",
    "print(gestures)\n",
    "#This will print all the name of the folder\n",
    "\n",
    "\n",
    "for ix in gestures:\n",
    "    print(ix)\n",
    "    #This will print all the available folder in Dataset folder\n",
    "    images = os.listdir(path + ix)\n",
    "    #This will get a list of files inside an ix folder which lies in dataset\n",
    "    os.mkdir(path2 + ix)\n",
    "    #this will create ix folders from dataset to path2 which is train folder\n",
    "    for cx in images:\n",
    "        print(cx)\n",
    "        #prints the name of all the images(cx) inside folder ix\n",
    "        img_path = path + ix +'/' + cx\n",
    "        #This is the path of an image inside ix folder which is present in dataset folder\n",
    "        img = cv2.imread(img_path)\n",
    "        #cv2.imread() method loads an image from the specified file\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.cvtColor() method is used to convert an image from one color space to another.\n",
    "        \"\"\"Syntax: cv2.cvtColor(src, code)\n",
    "        Parameters:\n",
    "        src: It is the image whose color space is to be changed.\n",
    "        code: It is the color space conversion code.\"\"\"\n",
    "        thresh = cv2.threshold(grey, 127, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "        \"\"\"Thresholding is the binarization of an image. In general, we seek to convert a grayscale image\n",
    "        to a binary image, where the pixels are either 0 or 255.\"\"\"\n",
    "        #cv2.THRESH_BINARY_INV is used to create binary image where object is black in color and background is white.\n",
    "        \"\"\"Otsu’s method assumes that our image contains two classes of pixels: the background and the foreground.\n",
    "        It Compute the threshold value T and Replace image pixels into white in those regions,\n",
    "        where saturation is greater than T and into the black in the opposite cases.\"\"\"\n",
    "        \"\"\"In Otsu Thresholding, a value of the threshold isn’t chosen but is determined automatically.\n",
    "        A bimodal image (two distinct image values) is considered. \n",
    "        The histogram generated contains two peaks. \n",
    "        So, a generic condition would be to choose a threshold value that lies in the middle of both the histogram \n",
    "        peak values.\"\"\"\n",
    "        save_img = cv2.resize(thresh, (50,50))\n",
    "        #uses the threshold value and resized it into 50x50 pixel size\n",
    "        cv2.imwrite(path2 + ix + '/' + cx, save_img)\n",
    "        #saves the image to \"train\" folder\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
