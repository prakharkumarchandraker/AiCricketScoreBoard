{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#............................................Training & Testing using deep learning......................................#\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Preprocessed/Train/' #To retrieve an image file from the \"Train\" directory within the \"Preprocessed\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = os.listdir(path) # creates a list of all files and directories at the specified file path, and assigns it to the variable 'gestures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = { # maps labels to specific keys using the pre-defined dictionary \"dict_labels\".\n",
    "    'out': 1, # the key 'out' is mapped to the integer value 1.\n",
    "    'noball': 2 # the key 'noball' is mapped to the integer value 2.\n",
    "   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['out', 'noball']\n"
     ]
    }
   ],
   "source": [
    "print(list(dict_labels.keys())) # prints a list of the keys in the dictionary \"dict_labels\", which in this case are 'out' and 'noball'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], [] # creates two empty lists named 'x' and 'y' and assigns them to the variables 'x' and 'y'.\n",
    "for ix in gestures: # This is a for loop in Python that loops through a list named \"gestures\" and assigns each element to the variable \"ix\".\n",
    "    images = os.listdir(path + ix) # retrieving a list of files and directories located in a folder obtained by combining a variable 'path' with the current element 'ix' in the loop, and saves the list to a variable 'images'\n",
    "    for cx in images: # Python loop iterates each \"images\" element, assigning to variable \"cx\"\n",
    "        img_path = path + ix + '/' + cx # creating a file path for a specific image by concatenating the strings 'path', 'ix', and 'cx', and stores it in the variable 'img_path'\n",
    "        img = cv2.imread(img_path, 0) # here OpenCV library's 'imread' function is used to read a grayscale image from the file path stored in 'img_path' and assigns it to the variable 'img'.\n",
    "        img = img.reshape((50,50,1)) # reshaping an image into a 3D array with dimensions 50x50x1.\n",
    "        img = img/255.0 # normalizes the pixel values of an image by scaling them down to a range of 0 to 1\n",
    "        x.append(img) # adds an image or array of pixel values to the end of a list.\n",
    "        y.append(dict_labels[ix]) # contains labels of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(x) # converts a list x into a NumPy array X\n",
    "Y = np.array(y) # converts a list y into a NumPy array Y\n",
    "Y = np_utils.to_categorical(Y) # puts the labels into ctegory example (1. no ball,2.out)\n",
    "print(type(Y),len(Y)) #  prints the data type and length of the variable.\n",
    "Y.shape # outputs the shape or dimensions of the NumPy array Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,8)) # creates a new Matplotlib figure with dimensions of 18 inches by 8 inches for plotting or visualizing data.\n",
    "sns.countplot(x=list(dict_labels.keys())) # sns (seabor) , creates a count plot using Seaborn to visualize the number of occurrences of each category key in a dictionary dict_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape # tells us how many elements are present along each axis or dimension in the NumPy array Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = Y.shape[1] # assigns the number of columns or categories present in the one-hot encoded NumPy array Y to the variable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(X, Y, random_state=0) # shuffles two NumPy arrays X and Y randomly in  with a seed value of 0 using shuffle() function from scikit-learn: X , (random state = 0) means how many times it is going to shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 50, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # returns the dimensions or shape of the NumPy array X, which has a length of 2000 in the first dimension (rows), and 50 in each of the remaining three dimensions (columns, height, and channel), where the last dimension represents the number of color channels in the image (1 for grayscale or 3 for RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3) # dividing the data into train,test,split ,This code uses the scikit-learn train_test_split() function to split two NumPy arrays X and Y into a training set and a testing set, with a 70/30 ratio and returns four arrays: X_train, X_test, Y_train, and Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 50, 50, 1) (600, 50, 50, 1)\n",
      "(1400, 3) (600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape) # prints the dimensions or shapes of the training and testing sets of the NumPy arrays X, which have 1400 and 600 rows, respectively, and a common shape of (50, 50, 1) representing the size of each image in the dataset.\n",
    "print(Y_train.shape, Y_test.shape) # prints the shapes of the training and testing sets of the one-hot encoded NumPy array Y, which have 1400 and 600 rows, respectively, and 3 columns representing the 3 categories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,083\n",
      "Trainable params: 206,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # using sequential model by importing the keras.models , from sequential model we are getting the object and the object name is smodel.\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(50,50 ,1) )) #convolutional contains multiple layer so the first layer is convo2D layer where we are passing the input where 64 is filter size, relu  is activation function and 3*3 is kernel size(to load data more memory is required)\n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) # adds a layer to the neural network model using Keras that performs max pooling, which reduces the size of the output from the previous layer by taking the maximum value within a 2x2 window. This helps to reduce the number of parameters and prevent overfitting.\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
    "\n",
    "model.add(Flatten()) # adds a flatten layer to the neural network model using Keras that converts the 2D input data into a 1D array, which can be passed to the next fully connected layer.\n",
    "model.add(Dense(128, activation = 'relu')) # dense layer is important layer main learning process goes on 128 is its memory size\n",
    "model.add(Dropout(0.20)) # adds a dropout layer to the neural network model using Keras that randomly sets 20% of the input units to 0 during each training epoch, which helps to reduce overfitting\n",
    "model.add(Dense(categories, activation = 'softmax')) # total no. of categories is passed for lassification\n",
    "\n",
    "model.summary() # displays a summary of the neural network model using Keras that includes the layers, output shape, number of parameters, and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', metrics=['accuracy'], loss='categorical_crossentropy') # compiles the neural network model using Keras with the Adam optimizer, 'accuracy' as the performance metric, and categorical crossentropy as the loss function to minimize during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 8s 558ms/step - loss: 0.4349 - accuracy: 0.8679 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 6s 558ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6665e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 5s 476ms/step - loss: 1.7212e-04 - accuracy: 1.0000 - val_loss: 1.9073e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 9.0148e-07 - accuracy: 1.0000 - val_loss: 1.1126e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 5s 474ms/step - loss: 5.8707e-07 - accuracy: 1.0000 - val_loss: 1.0331e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 5s 471ms/step - loss: 2.6192e-07 - accuracy: 1.0000 - val_loss: 1.0331e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 5s 473ms/step - loss: 2.8499e-07 - accuracy: 1.0000 - val_loss: 9.9341e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6510e-07 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, validation_data=[X_test, Y_test])# training process x_train contains data and y_train contains labels , epoch = 50 means 50 times iteration is done, 128 image it process ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy']) # plots the accuracy metric over the course of the training epochs, which allows us to visualize how well the model is learning from the training data\n",
    "plt.plot(history.history['val_accuracy']) #  plots the validation accuracy metric over the course of the training epochs, which allows us to visualize how well the model is generalizing to new, unseen data.\n",
    "plt.title(\"Accuracy\") # sets the title of the plot to \"Accuracy\".\n",
    "plt.xlabel('epoch') # sets the label of the x-axis of the plot to \"epoch\".\n",
    "plt.ylabel('accuracy') # sets the label of the y-axis of the plot to \"accuracy\".\n",
    "plt.legend(['train','test']) # adds a legend to the plot with the labels \"train\" and \"test\".\n",
    "plt.show() # displays the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN_model.h5') # Saves the trained CNN model to a file named 'CNN_model.h5' h5 is file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = load_model('CNN_model.h5') #  loads the saved CNN model from the 'CNN_model.h5' file into a variable named 'm'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = os.listdir('Test/') #  reads the names of all the files present in the 'Test/' directory and stores them in a list called 'test_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels # dict_labels refers to a dictionary containing the mapping of the categorical labels to their respective string labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in test_data: # for loop that iterates through each element in the test_data list.\n",
    "    print(ix) # nts the value of the variable ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], [] # initializes two empty lists, x and y.\n",
    "for ix in test_data: # for loop iterating over each file name in the test_data list.\n",
    "    images = os.listdir('Test/' + ix) #  lists all the files in the directory 'Test/' + ix, where ix is a string variable that represents a specific folder in the 'Test/' directory.For example, if ix is 'cat', the code will list all the files in the 'Test/cat' directory.\n",
    "    for cx in range(1,201): # for loop that runs 200 times, from cx = 1 to cx = 200. During each iteration of the loop, the code inside the loop is executed.\n",
    "        img_path = 'Test/' + ix + '/' + str(cx) + '.jpg' # Loop through each subdirectory in the Test directory, then loop through each of the 200 images in that subdirectory, constructing the file path for each image.\n",
    "        img = cv2.imread(img_path, 0) # reads an image using OpenCV library from the specified file path 'img_path' in grayscale mode, meaning the image will be loaded in black and white format.\n",
    "        img = img.reshape((50,50,1)) #  takes the image array img and reshapes it to a 3D array of shape (50,50,1), where the first two dimensions represent the image dimensions and the last dimension is the number of channels. Here, there is only one channel as the images are grayscale.\n",
    "        img = img/255.0 \n",
    "        x.append(img) \n",
    "        y.append(dict_labels[ix])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.array(x) # creates a numpy array X_t from the list x by converting it to a numpy array. This is often done to convert a list of arrays or values into a format that can be used in machine learning models. In this case, it is likely that x contains a list of images that have been preprocessed and resized for use in a machine learning model.\n",
    "y_t = np.array(y) \n",
    "Y_t = np_utils.to_categorical(y_t) # converts a class vector (integers) to binary class matrix. In other words, it converts the label (Y_t) into a one-hot encoding format so that the model can predict the label for each test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t.shape # means that the shape of the numpy array X_t is (400, 50, 50, 1), where 400 is the number of samples, 50 is the width and height of each image in pixels, and 1 represents that the images are grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_t) # code is using the trained model m to make predictions on the test data X_t and storing the predictions in the variable y_pred. The output shows that the predictions were made for 13 batches of test data and the processing time for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_t, y_pred.round()) # The accuracy_score function from the sklearn.metrics module is used to calculate the accuracy score between predicted y_pred and actual labels Y_t, which is stored in variable acc.\n",
    "print('Accuracy:', acc) # prints the string \"Accuracy:\" followed by the value of the variable acc, which is the accuracy score of the predicted labels compared to the actual labels. In this case, the accuracy is perfect (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred.round(), Y_t)) # The classification_report() function prints the precision, recall, and F1-score for each class and the overall accuracy of the model, based on the predicted and true labels of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
